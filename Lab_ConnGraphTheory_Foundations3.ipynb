{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations 3: Lab on connectivity and graph theory\n",
    "- Instructor: Ruben Sanchez-Romero\n",
    "- T.A: Lakshman Chakravarthula\n",
    "- Spring 2025 CMBN, Rutgers Newark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mathematical operations on arrays: https://numpy.org/\n",
    "import numpy as np \n",
    "\n",
    "# for plotting: https://matplotlib.org/\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for statistical analysis: https://scipy.org/\n",
    "from scipy import stats\n",
    "\n",
    "# for graph theory we will used a Python implementation of Brain Connectivity Toolbox BCT (Matlab native)\n",
    "# https://pypi.org/project/bctpy/\n",
    "# repository: https://github.com/aestrivex/bctpy (go here to explore the functions)\n",
    "# For documentation and search about functions see the website below:\n",
    "# https://sites.google.com/site/bctnet/ (Search bar in the top right)\n",
    "import bct as bct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build two graphical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define number of nodes\n",
    "num_nodes_model = 128\n",
    "\n",
    "print(f'num_nodes_model = {num_nodes_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define number of undirected edges (won't be covering directed networks in this lab)\n",
    "num_poss_edges_model = (num_nodes_model * (num_nodes_model-1))/2  # number of possible undirected edges\n",
    "density_model = 0.15 # density = % of num_poss_edges\n",
    "num_edges_model = int(np.round(num_poss_edges_model*density_model)) # round to get an integer\n",
    "\n",
    "print(f'num_poss_edges_model = {int(num_poss_edges_model)}')\n",
    "print(f'density_model = {density_model}')\n",
    "print(f'num_edges_model = {int(num_edges_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Call bct to generate a random network: it connects pair of nodes with the same probability p\n",
    "# (seed parameter is the random seed and it is used for reproducibility)\n",
    "graph_random_upt = bct.makerandCIJ_und(n=num_nodes_model,\n",
    "                                       k=num_edges_model, \n",
    "                                       seed = 100)\n",
    "\n",
    "# plot the resulting graph (binary: edge or no edge)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.spy(graph_random_upt)\n",
    "plt.title('random network: upper triangular')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see a general description of the function and the inputs (parameters) and outputs (returns),\n",
    "# use a question mark \"?\" next to the name of the function as below:\n",
    "bct.makerandCIJ_und?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.A. bct.makerandCIJ_und produces an upper triangular matrix. We want a symmetric matrix\n",
    "graph_random = (graph_random_upt + graph_random_upt.T) != 0 \n",
    "\n",
    "# plot the resulting graph (binary: edge or no edge)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.spy(graph_random)\n",
    "plt.title('random network: symmetric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Call bct to generate a modular small-world network\n",
    "# (sz_cl parameter defines the number of nodes in a clusters)\n",
    "graph_smallworld_dir = bct.makeevenCIJ(n = num_nodes_model, \n",
    "                                       k = num_edges_model*2, # to facilitate the symmetrization (see next cell)\n",
    "                                       sz_cl = 4, \n",
    "                                       seed = 100)\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.spy(graph_smallworld_dir)\n",
    "plt.title('small-world network: directed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.A. bct.makeevenCIJ produces a directed network, so we want to make it undirected and symmetric.\n",
    "\n",
    "# get the indices for the upper triangular only (this is why we double the number of edges above)\n",
    "ut_idx = np.triu_indices(num_nodes_model,k=1)\n",
    "aux = np.zeros((num_nodes_model,num_nodes_model))\n",
    "aux[ut_idx] = graph_smallworld_dir[ut_idx]\n",
    "graph_smallworld = (aux + aux.T)\n",
    "# and remove any edge (self-loop) in the diagonal. Set values in the diagonal to zero\n",
    "np.fill_diagonal(graph_smallworld,0)\n",
    "\n",
    "# plot the graph\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.spy(graph_smallworld)\n",
    "plt.title('small-world network: undirected and symmetric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute basic descriptive metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes, edges and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are working with symmetric matrices we can use numpy tools\n",
    "\n",
    "# first do it for the random network\n",
    "print(f'random network')\n",
    "\n",
    "# 1. Compute the number of nodes \n",
    "# np.shape output the size of the matrix (rows,columns), for our symmetric case rows = columns,\n",
    "# and they correspond to the number of nodes in the graph\n",
    "n_nodes = np.shape(graph_random)[0]\n",
    "print(f'number of nodes = {n_nodes}')\n",
    "# 2. Compute number of edges\n",
    "n_edges = np.sum(np.sum(graph_random != 0))/2\n",
    "print(f'number of edges = {int(n_edges)}')\n",
    "# 3. Compute density of the undirected network\n",
    "n_poss_edges = ((n_nodes)*(n_nodes-1))/2\n",
    "density = n_edges/n_poss_edges\n",
    "print(f'density = {density:.2f}')\n",
    "print('')\n",
    "\n",
    "# repeat for the small-world network\n",
    "print(f'small-world network')\n",
    "\n",
    "# 1. Compute the number of nodes \n",
    "n_nodes = np.shape(graph_smallworld)[0]\n",
    "print(f'number of nodes = {n_nodes}')\n",
    "# 2. Compute number of edges\n",
    "n_edges = np.sum(np.sum(graph_smallworld != 0))/2\n",
    "print(f'number of edges = {int(n_edges)}')\n",
    "# 3. Compute density of the undirected network\n",
    "n_poss_edges = ((n_nodes)*(n_nodes-1))/2\n",
    "density = n_edges/n_poss_edges\n",
    "print(f'density = {density:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### degree\n",
    "The degree of a node is the number of edges connected to such node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before we can use numpy tools to compute the degree of the undirected network\n",
    "# first do it for the random network\n",
    "print(f'random network')\n",
    "# 1. First compute the degree for each node independently\n",
    "# this will output a vector where each entry contains the degree of each ordered node\n",
    "degree_distribution_rd = np.sum(graph_random != 0, axis=1)\n",
    "\n",
    "# 2. We can do a histogram of the distribution to explore the variability of the degree across nodes\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(degree_distribution_rd,histtype='step')\n",
    "plt.title('random network: degree distribution')\n",
    "plt.show()\n",
    "\n",
    "# 3. Now compute the mean and standard deviation of the degree distribution\n",
    "degree_mean = np.mean(degree_distribution_rd)\n",
    "print(f'degree distribution mean = {degree_mean:.2f}')\n",
    "degree_stdev = np.std(degree_distribution_rd)\n",
    "print(f'degree distribution standard deviation = {degree_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "########\n",
    "# Repear for the small-world network\n",
    "\n",
    "print(f'small-world network')\n",
    "# 1. Compute degree distribution\n",
    "degree_distribution_sm = np.sum(graph_smallworld != 0, axis=1)\n",
    "# 2. Plot degree distribution\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(degree_distribution_sm,histtype='step',color='orange')\n",
    "plt.title('small-world network: degree distribution')\n",
    "plt.show()\n",
    "\n",
    "# 3. Mean and standard deviation of the degree distribution\n",
    "degree_mean = np.mean(degree_distribution_sm)\n",
    "print(f'degree distribution mean = {degree_mean:.2f}')\n",
    "degree_stdev = np.std(degree_distribution_sm)\n",
    "print(f'degree distribution standard deviation = {degree_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "# 4. we can overlap the histograms to visualize the differences in the distributions\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(degree_distribution_rd,histtype='step',label='random')\n",
    "plt.hist(degree_distribution_sm,histtype='step',color='orange',label='small-world')\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.title('Comparison of degree distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the degree function in bct\n",
    "# see https://github.com/aestrivex/bctpy/blob/master/bct/algorithms/degree.py\n",
    "# and find the function \"degrees_und\" to see how it was computed\n",
    "\n",
    "deg_dist = bct.degrees_und(graph_random)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(deg_dist,histtype='step')\n",
    "plt.title('random network: degree distribution')\n",
    "plt.show()\n",
    "deg_mean = np.mean(deg_dist)\n",
    "print(f'degree distribution mean = {deg_mean:.2f}')\n",
    "deg_stdev = np.std(deg_dist)\n",
    "print(f'degree distribution standard deviation = {deg_stdev:.2f}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Theory measures\n",
    "For the full list of available measures go to https://sites.google.com/site/bctnet/list-of-measures?authuser=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering coefficient\n",
    "The clustering coefficient measures the fraction of nodeâ€™s neighbors that are neighbors of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"clustering_coefficient.png\"  width=\"600\" height=\"211\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recent paper using clustering coefficient:\n",
    "# Kustermann, Thomas, et al. \"Brain functional connectivity during the first day of coma reflects long-term outcome.\" \n",
    "# NeuroImage: Clinical 27 (2020): 102295.\n",
    "# https://doi.org/10.1016/j.nicl.2020.102295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we did for degree, compute the distribution, plot it and then compute the mean and standard deviation\n",
    "\n",
    "# First for the random network\n",
    "# distribution of the clustering coefficient\n",
    "cluster_coeff_dist_rd = bct.clustering_coef_bu(graph_random)\n",
    "# plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(cluster_coeff_dist_rd,histtype='step')\n",
    "plt.title('random network: clustering coefficient distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "cc_mean = np.mean(cluster_coeff_dist_rd)\n",
    "print(f'clustering coefficient distribution mean = {cc_mean:.2f}')\n",
    "cc_stdev = np.std(cluster_coeff_dist_rd)\n",
    "print(f'clustering coefficient distribution standard deviation = {cc_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "# Now for the small world network\n",
    "cluster_coeff_dist_sm = bct.clustering_coef_bu(graph_smallworld)\n",
    "# plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(cluster_coeff_dist_sm,histtype='step',color='orange')\n",
    "plt.title('small-world network: clustering coefficient distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "cc_mean = np.mean(cluster_coeff_dist_sm)\n",
    "print(f'clustering coefficient distribution mean = {cc_mean:.2f}')\n",
    "cc_stdev = np.std(cluster_coeff_dist_sm)\n",
    "print(f'clustering coefficient distribution standard deviation = {cc_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "# we can overlap the histograms to visualize the differences in the distributions\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(cluster_coeff_dist_rd,histtype='step',label='random')\n",
    "plt.hist(cluster_coeff_dist_sm,histtype='step',color='orange',label='small-world')\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.title('Comparison of clustering coefficient distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest path length and characteristic path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here a recent paper using characteristic path length (in the context of small-world networks)\n",
    "# Luppi, Andrea I., et al. \"LSD alters dynamic integration and segregation in the human brain.\" \n",
    "# NeuroImage 227 (2021): 117653.\n",
    "# https://doi.org/10.1016/j.neuroimage.2020.117653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shortest path length between two nodes is the minimum number of edges \n",
    "# that have to be traversed to go from one node to the other\n",
    "\n",
    "# Use the distance function to compute the shortest path length between all pair of nodes.\n",
    "# The output is a distance matrix where mat(i,j) is the shortest path length\n",
    "\n",
    "# Obtain the distance matrix for the random network\n",
    "dist_mat_rd = bct.distance_bin(graph_random)\n",
    "# plot the distance matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(dist_mat_rd)\n",
    "# to show the colorbar\n",
    "plt.colorbar()\n",
    "plt.title('distance matrix for random network')\n",
    "plt.show()\n",
    "\n",
    "# Now for small-world network\n",
    "dist_mat_sm = bct.distance_bin(graph_smallworld)\n",
    "# plot the distance matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(dist_mat_sm)\n",
    "# to show the colorbar\n",
    "plt.colorbar()\n",
    "plt.title('distance matrix for small-world network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It also useful to visualize this information as a distribution\n",
    "# in this case the shortest path length distribution of the network\n",
    "\n",
    "# Since this is a symmetric matrix we can only take the upper triangular elments of the matrix.\n",
    "# We also do not care about the diagonal mat(i,i), for which the shortest path length is set as zero\n",
    "\n",
    "# First find the indices of the upper triangular elements\n",
    "ut_idx = np.triu_indices(num_nodes_model,k=1)\n",
    "\n",
    "# plot the distribution for random network\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(dist_mat_rd[ut_idx],histtype='step')\n",
    "plt.title('random network: shortest path length distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "spl_mean = np.mean(dist_mat_rd[ut_idx])\n",
    "print(f'shortest path length distribution mean = {spl_mean:.2f}')\n",
    "spl_stdev = np.std(dist_mat_rd[ut_idx])\n",
    "print(f'shortest path length distribution standard deviation = {spl_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "# plot the distribution for small-world network\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(dist_mat_sm[ut_idx],histtype='step',color='orange')\n",
    "plt.title('small-world network: shortest path length distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "spl_mean = np.mean(dist_mat_sm[ut_idx])\n",
    "print(f'shortest path length distribution mean = {spl_mean:.2f}')\n",
    "spl_stdev = np.std(dist_mat_sm[ut_idx])\n",
    "print(f'shortest path length distribution standard deviation = {spl_stdev:.2f}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### characteristic path length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The characteristic path length is the average shortest shortest path length in the network\n",
    "# As you can see, we computed it above as the mean of the upper triangular of the distance matrix\n",
    "\n",
    "# We can use bct.charpath to compute it. It takes as input a distance matrix (as the one computed above)\n",
    "# Note the [0] at the end to indicate that we only want the first output of the function.\n",
    "# You can explore the function (bct.charpath?) to see the rest of the outputs.\n",
    "\n",
    "# compute for the random network\n",
    "charpath_rd = bct.charpath(dist_mat_rd,include_diagonal=False)[0]\n",
    "print(f'random network characteristic path length = {charpath_rd:.2f}')\n",
    "\n",
    "# and for the small-world network\n",
    "charpath_sm = bct.charpath(dist_mat_sm,include_diagonal=False)[0]\n",
    "print(f'small-world network characteristic path length = {charpath_sm:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A property of small-world networks is that they have\n",
    "# a small characteristc path length (average shortest path length) AND a large average clustering coefficient\n",
    "\n",
    "print('Small-world network')\n",
    "print(f'-characteristic path length = {charpath_sm:.2f}')\n",
    "print(f'-average clustering coefficient = {np.mean(cluster_coeff_dist_sm):.2f}')\n",
    "print('')\n",
    "print('Random network')\n",
    "print(f'-characteristic path length = {charpath_rd:.2f}')\n",
    "print(f'-average clustering coefficient = {np.mean(cluster_coeff_dist_rd):.2f}')\n",
    "\n",
    "# A paper about small-world networks in brain models\n",
    "# Bassett, D. S., & Bullmore, E. T. (2017). Small-world brain networks revisited. The Neuroscientist, 23(5), 499-516.\n",
    "# https://doi.org/10.1177/1073858416667720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness centrality\n",
    "Node betweenness centrality is the fraction of all shortest paths in the network that contain a given node. Nodes with high values of betweenness centrality participate in a large number of shortest paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here a recent paper using betweenness centrality:\n",
    "# Soman, Shania Mereen, et al. \n",
    "# \"Functional and structural brain network development in children with attention deficit hyperactivity disorder.\" \n",
    "# Human Brain Mapping (2023).\n",
    "# https://doi.org/10.1002/hbm.26288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bct.betweenness function compute the betweeness centrality for each node in the graph.\n",
    "\n",
    "# Compute for the random network, plot the distribution, and meand and standard deviation\n",
    "betw_cent_rd = bct.betweenness_bin(graph_random)\n",
    "# plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(betw_cent_rd,histtype='step')\n",
    "plt.title('random network: betweenness centrality distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "bc_mean = np.mean(betw_cent_rd)\n",
    "print(f'betweenness centrality distribution mean = {bc_mean:.2f}')\n",
    "bc_stdev = np.std(betw_cent_rd)\n",
    "print(f'betweenness centrality distribution standard deviation = {bc_stdev:.2f}')\n",
    "print('')\n",
    "\n",
    "# now for the small-world network\n",
    "betw_cent_sm = bct.betweenness_bin(graph_smallworld)\n",
    "# plot\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(betw_cent_sm,histtype='step',color='orange')\n",
    "plt.title('small-world network: betweenness centrality distribution')\n",
    "plt.show()\n",
    "# mean and standard deviation\n",
    "bc_mean = np.mean(betw_cent_sm)\n",
    "print(f'betweenness centrality distribution mean = {bc_mean:.2f}')\n",
    "bc_stdev = np.std(betw_cent_sm)\n",
    "print(f'betweenness centrality distribution standard deviation = {bc_stdev:.2f}')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Null models\n",
    "In order to test if graph theory metrics for a particular network are significantly different from a network without structure, we can use the idea of null models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the small-world network from the previous sections.\n",
    "# We want to keep the number of nodes and number of edges, but we want to destroy the structure.\n",
    "\n",
    "# One way to destroy the structure is randomize the order of the edges across the network\n",
    "\n",
    "n_nodes = np.shape(graph_smallworld)[0]\n",
    "# allocate memory for the null model network (in matrix form)\n",
    "null_model = np.zeros((n_nodes,n_nodes))\n",
    "# the undirected network is symmetric so we can do this process only for the upper triangular\n",
    "# and then symmetrize back\n",
    "# Get indices of the upper triangular elements\n",
    "ut_idx = np.triu_indices(n_nodes,k=1)\n",
    "# extract the 1/0s of the upper triangular (1-edge, 0-no edge)\n",
    "edges_vector = graph_smallworld[ut_idx]\n",
    "# randomize the order of the edges\n",
    "np.random.seed(100) # use this for this lab reproducibility\n",
    "rand_edges_vector = np.random.choice(edges_vector, size=len(edges_vector), replace=False)\n",
    "# now assign this vector to the null model\n",
    "null_model[ut_idx] = rand_edges_vector\n",
    "# and symmetrize\n",
    "null_model = (null_model + null_model.T) != 0\n",
    "\n",
    "# plot the small-world network vs its null model\n",
    "plt.figure(figsize=(10,5))\n",
    "# use the next to make a mosaic of plots\n",
    "plt.subplot(1,2,1)\n",
    "plt.spy(graph_smallworld)\n",
    "plt.title('small-world network')\n",
    "plt.subplot(1,2,2)\n",
    "plt.spy(null_model)\n",
    "plt.title('null model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# compare the mean degree, mean clustering coefficient, characteristic path length and mean betweeness centrality\n",
    "print('')\n",
    "print('small-world network:')\n",
    "print(f'-mean degree = {np.mean(bct.degrees_und(graph_smallworld)):.2f}')\n",
    "print(f'-mean clustering coefficient = {np.mean(bct.clustering_coef_bu(graph_smallworld)):.2f}')\n",
    "print(f'-characteristic path length = {bct.charpath(bct.distance_bin(graph_smallworld))[0]:.2f}')\n",
    "print(f'-mean betweenness centrality = {np.mean(bct.betweenness_bin(graph_smallworld)):.2f}')\n",
    "\n",
    "print('')\n",
    "print('null model:')\n",
    "print(f'-mean degree = {np.mean(bct.degrees_und(null_model)):.2f}')\n",
    "print(f'-mean clustering coefficient = {np.mean(bct.clustering_coef_bu(null_model)):.2f}')\n",
    "print(f'-characteristic path length = {bct.charpath(bct.distance_bin(null_model))[0]:.2f}')\n",
    "print(f'-mean betweenness centrality = {np.mean(bct.betweenness_bin(null_model)):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation testing\n",
    "\n",
    "In order to obtain a statistically significant comparison of graph theory metrics, we can use a permutation test in which we produce a series of N null models and compare our graph metrics to those of the null model distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above we need to create a null model but this time we need to repeat that process N times.\n",
    "\n",
    "# It is easier to create a function that generates a null model and then call that function the times\n",
    "# we need it. See above for the description of each step in the function.\n",
    "\n",
    "def null_model_generator(graph):\n",
    "    n_nodes = np.shape(graph)[0]\n",
    "    null_model = np.zeros((n_nodes,n_nodes))\n",
    "    ut_idx = np.triu_indices(n_nodes,k=1)\n",
    "    edges_vector = graph[ut_idx]\n",
    "    # randomize the order of the edges\n",
    "    rand_edges_vector = np.random.choice(edges_vector, size=len(edges_vector), replace=False)\n",
    "    # assign the randomized edges to the upper triangular\n",
    "    null_model[ut_idx] = rand_edges_vector\n",
    "    # make a symmetric matrix\n",
    "    null_model = (null_model + null_model.T) != 0\n",
    "    \n",
    "    return null_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make a for-loop that calls the null_model_generator function N times\n",
    "number_permutations = 1000\n",
    "# we need this to define the array to allocate the N null models\n",
    "n_nodes = np.shape(graph_smallworld)[0]\n",
    "# allocate an array to save all the N null models: size = nodes x nodes x number of permutations\n",
    "null_model_all = np.zeros((n_nodes,n_nodes,number_permutations))\n",
    "# loop \n",
    "for N in range(number_permutations):\n",
    "    null_model_all[:,:,N] = null_model_generator(graph_smallworld)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using null_model_all we can compute the metrics of interest and create a \"null distribution\" for each metric.\n",
    "# We are interested in:\n",
    "# mean clustering coefficient\n",
    "# characteristic path length\n",
    "# mean betweenness centrality\n",
    "# We do not care about mean degree because by construction of the null model, this will be the same\n",
    "\n",
    "# allocate space for the results\n",
    "null_distribution_meanCC = np.zeros((number_permutations,1))\n",
    "null_distribution_ChPL = np.zeros((number_permutations,1)) \n",
    "null_distribution_meanBwC = np.zeros((number_permutations,1))\n",
    "\n",
    "# compute the metric of interest for each null model\n",
    "for N in range(number_permutations):\n",
    "    null_distribution_meanCC[N] = np.mean(bct.clustering_coef_bu(null_model_all[:,:,N]))\n",
    "    null_distribution_ChPL[N] = bct.charpath(bct.distance_bin(null_model_all[:,:,N]))[0]\n",
    "    null_distribution_meanBwC[N] = np.mean(bct.betweenness_bin(null_model_all[:,:,N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine if our small-world metrics are significantly different from a model without structure (null model)\n",
    "# we can do the next computation\n",
    "# permutation p-value = #(metric_nullmodel_n > metric_smallworld) / (number of permutations)\n",
    "# In words, \n",
    "# the number of times our N null model metrics are > than the small-world metric, divided by the number of permutations\n",
    "\n",
    "# let's do it first for clustering coefficient\n",
    "# compute the metric of interest for the small-world network\n",
    "smallworld_meanCC = np.mean(bct.clustering_coef_bu(graph_smallworld))\n",
    "# compute the permutation p-value\n",
    "pval_meanCC = np.sum(null_distribution_meanCC > smallworld_meanCC)/number_permutations\n",
    "print(f'pval for small-world graph mean clustering coefficient = {pval_meanCC}')\n",
    "# plot the null distribution for the mean clustering coefficient\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(null_distribution_meanCC,histtype='step',color='black')\n",
    "plt.title('null distribution of mean clustering coefficient')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(null_distribution_meanCC,histtype='step',color='black')\n",
    "plt.title('null distribution of mean clustering coefficient\\n and small-world clustering coefficient')\n",
    "# add a vetical line indicating the position of the small-world mean clustering coefficient\n",
    "plt.axvline(smallworld_meanCC,color='red')\n",
    "plt.show()\n",
    "\n",
    "# now repeat for the other metrics\n",
    "smallworld_ChPL = bct.charpath(bct.distance_bin(graph_smallworld))[0]\n",
    "pval_ChPL = np.sum(null_distribution_ChPL > smallworld_ChPL)/number_permutations\n",
    "print(f'pval for small-world graph characterstic path length = {pval_ChPL}')\n",
    "# plot the null distribution for the characteristic path length\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(null_distribution_ChPL,histtype='step',color='black')\n",
    "plt.title('null distribution of characteristic path length')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(null_distribution_ChPL,histtype='step',color='black')\n",
    "plt.title('null distribution of characteristic path length\\n and small-world characteristic path length')\n",
    "# add a vetical line indicating the position of the small-world characteristic path length\n",
    "plt.axvline(smallworld_ChPL,color='red')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "smallworld_meanBwC = np.mean(bct.betweenness_bin(graph_smallworld))\n",
    "pval_meanBwC = np.sum(null_distribution_meanBwC > smallworld_meanBwC)/number_permutations\n",
    "print(f'pval for small-world graph mean betweenness centrality = {pval_meanBwC}')\n",
    "# plot the null distribution for the mean betweenness centrality\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(null_distribution_meanBwC,histtype='step',color='black')\n",
    "plt.title('null distribution of mean betweenness centrality')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(null_distribution_meanBwC,histtype='step',color='black')\n",
    "plt.title('null distribution of mean betweenness centrality\\n and small-world betweenness centrality')\n",
    "# add a vetical line indicating the position of the small-world mean betweenness centrality\n",
    "plt.axvline(smallworld_meanBwC,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Starting from data collected from a system of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are researchers that go out and collect data from a system of interest (eg. a human brain).<br>\n",
    "We hypothesized that the brain is organized as a network and thus want to explore properties of that network.<br>\n",
    "- To do so, we first need to define our NODES (eg. brain regions), and obtain data for those nodes,\n",
    "(eg. BOLD timeseries)<br>\n",
    "- Second, we need to define our EDGES (eg. functional connections), and estimate them from the nodes' data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's simulate a system of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's simulate this situation using a small-world network and creating data for it.\n",
    "# Let's keep the same parameters as above for the graph.\n",
    "# IMPORTANT! This time we want the \"directed graph\", in order to have a causal model to simulate data\n",
    "\n",
    "graph_smallworld_directed = bct.makeevenCIJ(n = num_nodes_model, \n",
    "                                       k = num_edges_model*2, \n",
    "                                       sz_cl = 4, \n",
    "                                       seed = 100)\n",
    "\n",
    "\n",
    "# Now we are going to assign random weights to those binary edges\n",
    "\n",
    "# First build a weights matrix populated with values from a uniform distribution from +0.1 to +0.7\n",
    "# get the number of nodes of our graphical model to define the size of the weights matrix\n",
    "n_nodes = np.shape(graph_smallworld_directed)[0]\n",
    "np.random.seed(70) # for this lab reproducibility\n",
    "weights_matrix = np.random.uniform(0.1,0.7,size=(n_nodes,n_nodes))\n",
    "# now multiply the binary graph (1/0s) by the weights matrix to get only weights for the edges (1s)\n",
    "# Let's call this directed weighted graph W\n",
    "W = np.multiply(graph_smallworld_directed,weights_matrix)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(graph_smallworld_directed,aspect='auto',cmap='binary')\n",
    "plt.title('directed binary small-world network')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(weights_matrix,aspect='auto')\n",
    "plt.title('weights sample')\n",
    "plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(W,aspect='auto')\n",
    "plt.title('directed weighted small-world network W')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create data using the directed weighted model\n",
    "\n",
    "# We are using the next linear model X = WX + E\n",
    "# Where X is our dataset (nodes x datapoints), W is the directed weighted matrix (nodes x nodes),\n",
    "# and E are the intrinsic noise for each node. For example, for a node X that is an effect of Y in the network,\n",
    "# Y -> X, the linear model is defined as  X = wY + Ex, where w is the weight of the connection,\n",
    "# and Ex is the intrinsic noise for node X (ie. the activity of X that does not depend on any other node)\n",
    "\n",
    "# 1. Define E, the intrinsic noise\n",
    "# First define the sample size. Let's use 800, which is a not uncommon size in fMRI data\n",
    "sample_size = 800 # number of datapoints\n",
    "# We will sample the datapoints from a Normal Gaussian distribution with mean 0 and standard deviation 1\n",
    "np.random.seed(60) # for this lab reproducibility\n",
    "E = np.random.normal(0,1,size=(n_nodes,sample_size))\n",
    "\n",
    "# 2. In order to generate X, we need to solve the above model as X = inverse(I-W)E\n",
    "# I is the identity matrix\n",
    "I = np.identity(n_nodes)\n",
    "# solve X = inverse(I-W)E\n",
    "X = np.dot(np.linalg.inv(I-W),E)\n",
    "# Finally let's standardize each node independently to get them in the same scale (mean=0, std.dev=1)\n",
    "X = stats.zscore(X,axis=1)\n",
    "\n",
    "# 3. Let's plot a couple of the nodes dataseries\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(X[0,:])\n",
    "plt.title('node-0 dataseries')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(X[100,:],color='green')\n",
    "plt.title('node-100 dataseries')\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From dataset X, let's estimate a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we collected data X (here via simulation), we want to estimate a network\n",
    "# the describes the interactions between nodes in X.\n",
    "\n",
    "# Given that our nodes have linear Gaussian dataseries (X), we can use Pearson's correlation\n",
    "# to get a measure of the statistical association between nodes.\n",
    "\n",
    "# This measure of association will represent the EDGES of our network.\n",
    "\n",
    "# (In the context of brain analysis, the Pearson correlation between nodes (brain regions)\n",
    "# is usually referred as functional connectivity (FC).\n",
    "# As mentioned in the fMRI lab there are plenty other methods to estimate FC, but for simplicity\n",
    "# and given that correlation is still the field standard, let's use it here.)\n",
    "\n",
    "# compute the Pearson correlation for dataset X to produce an undirected estimate of the network\n",
    "estim_network = np.corrcoef(X)\n",
    "# in network estimation we usually set the diagonal to zero. Except if we are considering self-loops.\n",
    "np.fill_diagonal(estim_network,0)\n",
    "\n",
    "# plot the estimated network\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(estim_network,cmap='seismic')\n",
    "plt.title('estimated network\\n using Pearson correlation')\n",
    "plt.colorbar() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see from the plots above, this is a full matrix, meaning all entries are non-zero.\n",
    "# This kind of network is not useful for brain network analysis, since everything is connected with everything,\n",
    "# A common approach to solve this problem is to threshold the network, by taking for example,\n",
    "# the strongest positive edges until we reach a desired density.\n",
    "\n",
    "# For this lab, let's go with a target density of 20%\n",
    "num_nodes = np.shape(estim_network)[0]\n",
    "num_possible_edges = (num_nodes*(num_nodes-1))/2\n",
    "target_density = 0.20\n",
    "num_target_edges = int(target_density*num_possible_edges)\n",
    "print('Thresholding of estimated network')\n",
    "print(f'-target density = {target_density:.2f}')\n",
    "\n",
    "# It is common in brain network analysis to take only the positive FCs, let's do that here.\n",
    "# First order the edges correlation values from larger to smaller, do not consider 0s (non-edges).\n",
    "# Just take the upper triangular to avoid repeating values (due to symmetry) in the sorting.\n",
    "ut_idx = np.triu_indices(num_nodes,k=1)\n",
    "ordered_edges = np.flip(np.sort(estim_network[ut_idx][estim_network[ut_idx]>0]))\n",
    "# take the value corresponding to the num_target_edges to use as a cutoff\n",
    "cutoff = ordered_edges[num_target_edges]\n",
    "# threshold the network using the cutoff\n",
    "thresh_network = np.multiply(estim_network,(estim_network > cutoff))\n",
    "# compute the density of the thresholded network to verify\n",
    "density_thresh_network = (np.sum(np.sum(thresh_network!=0))/2)/num_possible_edges\n",
    "print(f'-density of the thresholded network = {density_thresh_network:.2f}')\n",
    "\n",
    "# Finally make a binary version to compute the graph metrics as above\n",
    "th_net_binary = (thresh_network != 0)\n",
    "\n",
    "# plot the thresholded network\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(thresh_network,cmap='Reds')\n",
    "plt.title('thresholded network')\n",
    "plt.colorbar() \n",
    "plt.subplot(1,2,2)\n",
    "plt.spy(th_net_binary)\n",
    "plt.title('binary thresholded network')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's compute the metrics of interest for the thresholded network\n",
    "Mean Degree, Mean Clustering Coefficient, Characteristic Path Length and Mean Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also explore the distributions here as we did above\n",
    "th_net_degree = bct.degrees_und(th_net_binary)\n",
    "th_net_clusteringCoefficient = bct.clustering_coef_bu(th_net_binary)\n",
    "th_net_charPathLength = bct.charpath(bct.distance_bin(th_net_binary))[0]\n",
    "th_net_btwCentrality = bct.betweenness_bin(th_net_binary)\n",
    "\n",
    "print('')\n",
    "print('Estimated thresholded network:')\n",
    "print(f'-mean degree = {np.mean(th_net_degree):.2f}')\n",
    "print(f'-mean clustering coefficient = {np.mean(th_net_clusteringCoefficient):.2f}')\n",
    "print(f'-characteristic path length = {th_net_charPathLength:.2f}')\n",
    "print(f'-mean betweenness centrality = {np.mean(th_net_btwCentrality):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare these values against the ones of the true network simulated \"graph_smallworld_directed\"\n",
    "\n",
    "# we need to make it undirected and symmetric first.\n",
    "true_model_undirected = (graph_smallworld_directed + graph_smallworld_directed.T) != 0\n",
    "\n",
    "\n",
    "true_model_degree = bct.degrees_und(true_model_undirected)\n",
    "true_model_clusteringCoefficient = bct.clustering_coef_bu(true_model_undirected)\n",
    "true_model_charPathLength = bct.charpath(bct.distance_bin(true_model_undirected))[0]\n",
    "true_model_btwCentrality = bct.betweenness_bin(true_model_undirected)\n",
    "\n",
    "print('')\n",
    "print('True model undirected:')\n",
    "print(f'-mean degree = {np.mean(true_model_degree):.2f}')\n",
    "print(f'-mean clustering coefficient = {np.mean(true_model_clusteringCoefficient):.2f}')\n",
    "print(f'-characteristic path length = {true_model_charPathLength:.2f}')\n",
    "print(f'-mean betweenness centrality = {np.mean(true_model_btwCentrality):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a non-parametric test to determine if the distribution of a graph metric is significantly different \n",
    "# between the estimated thresholded network and the true network.\n",
    "\n",
    "# Intuitively, we want to determine if (degree of true model - degree of estimated network) = 0\n",
    "# Formally, we are asking if the difference is centered around zero.\n",
    "\n",
    "# In this particular case, we would want this difference to be centered around zero,\n",
    "# suggesting we recovered network properties of the true model.\n",
    "# In other cases, for example, comparing two different groups (experimental/control),\n",
    "# we would expect the difference to NOT be centered around zero.\n",
    "\n",
    "# Let's make an example with the Degree\n",
    "# using the stats.wilcoxon function (more here https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test)\n",
    "# For more info. about the Wilcoxon signed-rank test: \n",
    "# https://www.sciencedirect.com/topics/mathematics/wilcoxon-signed-rank-test\n",
    "\n",
    "print(f'test for the null hypothesis H0: (degree of true model - degree of estimated network) = 0')\n",
    "difference = true_model_degree - th_net_degree\n",
    "wilcoxon_test = stats.wilcoxon(difference, alternative='two-sided')\n",
    "print(wilcoxon_test)\n",
    "print('')\n",
    "print(f'The pval < 0.001 give us some credence to reject H0')\n",
    "print(f'and conclude that the degree distribution is different between the estimated and the true network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the difference (true_model_degree - th_net_degree), for an intuitive visualization\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(difference,histtype='step')\n",
    "plt.title('distribution of the degree difference\\n and median of the distribution')\n",
    "plt.axvline(np.median(difference),color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
